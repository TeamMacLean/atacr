---
title: "Using atacr for Enriched ATAC-seq analysis"
author: "Dan MacLean"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{atacr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding[utf8]{inputenc}
---

_atacr_ is a package, currently under development for creating statistics and diagnostic plots for short read sequence data from enriched ATAC-seq experiments.

The basic input to _atacr_ functions is a long format dataframe [Wickham 2014](https://www.jstatsoft.org/article/view/v059i10), with column names:

* Bait `<factor>` the name of the bait
* Sample `<factor>` the name of the sample
* MeanCoverage `<numeric double>` (0..Inf) average number of reads mapping over each position in the bait
* BreadthCoverage `<numeric double>` (0..100) Percent of positions in the base covered with reads
* Read Count `<numeric integer>` (0..Inf) Number of reads mapping to the bait region

A built-in dataset, called `tenbaits_threesamples` which has made-up data for ten baits in three samples, is included as an example. This is a meaningless small data included only to show the functionality of the package. 

```{r}
library(atacr)
str(tenbaits_threesamples)
```

## Workflow
Analysing the data takes a few steps:

1. Normalise
2. Examine between sample variability
3. Estimate which baits are 'off' or 'closed'
4. Calculate likelihood of observing number of reads at each bait.

### Normalising the data

The normalisation step is done to allow us to compare between samples more easily. It does not directly impact the likelihood step. The purpose is to create plots that can show the integrity of the data and variability between samples. 

Use the function `atacr::quick_normalize(df, "control_sample_name")`

```{r}
norm <- atacr::quick_normalize(tenbaits_threesamples, "S1")
str(norm)
```

Some columns are renamed:

* `MeanCoverage` _becomes_ `sample_bait_mean_coverage`
* `ReadCount` _becomes_ `sample_bait_read_count`
* `BreadthCoverage` _becomes_ `sample_bait_breadth`

Some columns are new:

* `sample_mean_read_count` - the arithmetic mean read count for that sample
* `Control` - the samples used as control
* `control_bait_mean_coverage` - the mean coverage for the bait on that row in the control sample
* `control_bait_breadth` - the breadth of coverage for that bait in the control sample
* `control_bait_read_count` - the read count for that bait in the control sample
* `control_mean_read_count` - the mean read count in the control sample
* `read_count_ratio`- `sample_bait_read_count / control_bait_read_count`
* `sample_mean_ratio` - mean of `read_count_ratio` in that sample
* `normalized_value` - `read_count_ratio / sample_mean_ratio`
* `log_normalized_value` - `log2(normalized_value)`

### Examine between sample variability

#### The control ratio intensity plot
This allows you to visualise whether ratio of the sample read count to control read count is affected by the read count. 

```{r}
atacr::control_ratio_intensity_plot(norm)
```


#### All Vs All Read Count plots
This allows you to highlight any samples that do not seem to have the same variability or are in different ranges to others.

```{r}
atacr::all_versus_all_read_count_plot(norm)
```

```{r}
atacr::all_versus_all_normalized_plot(norm)
```

### Estimate negative control baits

It is important to have a list of baits that we know to be covering closed chromatin. The read counts from these baits should be very low. We actually don't in the current experiment know any baits to be closed, but we can bootstrap what we presume to be a low enough read count to be effectively off. 

```{r}
norm_neg <- atacr::find_negative_control_baits(
      norm,
      mean_depth = 2, 
      breadth = 50, 
      max_sample_percent = 100
  )
```
The function asks for:

1. The `norm` normalised dataframe
2. `mean_depth` - the _maximum_ mean depth a negative control bait may have
3. `breadth` - the _maximum_ breadth a negative control may have
4. `max_sample_percent` - the maximum proportion of samples in which that the bait appears to be a negative control. This ensures that the bait is functional and has coverage in at least some samples.

`max_sample_percent` may be replaced with `max_sample_count` by using `use_max_sample_count = TRUE`


You can find a summary of the negative controls you found in each sample with `count_negatives_found()`

```{r}
atacr::count_negatives_found(norm_neg)
```

You can plot the difference in means between the negative control baits and the rest with `atacr::negative_mean_plots(norm_neg)`

```{r}
atacr::negative_mean_plots(norm_neg)
```

Iterate this step until the number of negative controls is sensibly high and the separation between negative controls and the rest is good.

### Calculate likelihood of read counts at each bait based on counts in negative controls

To generate the Poisson probability of the observed read counts at each bait in each sample based on the negative controls in that sample use `likelihood()`

```{r}
like <- atacr::likelihood(norm_neg)
str(like)
```

This will give you the `norm_neg` dataframe with two new columns:

* `p` - the raw _p_-value of the observed read counts
* `corrected_p` - the Bonferroni corrected _p_-value.
